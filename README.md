Aqui est√° o `README.md` refinado, com as se√ß√µes duplicadas consolidadas e todos os tra√ßos de IA e linhas horizontais removidos, pronto para o seu reposit√≥rio.

-----

# üß† Desafio T√©cnico ‚Äî API de Classifica√ß√£o de Sa√∫de

Este reposit√≥rio cont√©m a solu√ß√£o completa para um **desafio t√©cnico de Machine Learning**.
O objetivo foi **construir um pipeline funcional de ponta a ponta**, capaz de ler, processar e interpretar hist√≥ricos de chat cl√≠nico para **identificar condi√ß√µes de sa√∫de** dos clientes ‚Äî tudo integrado a uma **API Flask pronta para consumo.**

## üéØ O Desafio

O objetivo foi desenvolver um modelo de NLP para classificar condi√ß√µes de sa√∫de (Obesidade, Diabetes, etc.) com base em hist√≥ricos de chat. A entrega √© uma **API Flask** que recebe um `client_id`, retorna uma lista de condi√ß√µes previstas e trata o erro `404 Not Found`.

Conforme a expectativa do desafio, o foco principal foi **demonstrar um processo claro de investiga√ß√£o**, tomada de decis√£o e a constru√ß√£o de um pipeline *end-to-end* funcional.

## üí° Abordagem e Metodologia

Desenvolvi o projeto seguindo uma **linha l√≥gica de investiga√ß√£o e prototipagem r√°pida**, priorizando clareza e reprodutibilidade.

### 1\. üîç Explora√ß√£o e Pr√©-Processamento (EDA)

  * **An√°lise de relacionamentos** entre os CSVs (`client`, `chat_history`, `client_conditions`, `seed_*`), mapeando chaves e integridades.
  * **Identifica√ß√£o do alvo (`y`)**: o arquivo `client_conditions.csv` foi definido como r√≥tulo do modelo.
  * **Entendimento dos dicion√°rios (`seed_*`)**: interpretados como tabelas de refer√™ncia, √∫teis para enriquecer e validar as condi√ß√µes de sa√∫de.

### 2\. üß± Engenharia de Features (Prepara√ß√£o do X)

  * Para preservar o contexto do di√°logo, as mensagens foram **ordenadas por data** e **prefixadas** com o remetente (`client:` ou `user:`).
  * Todas as mensagens de um cliente foram **concatenadas** em um √∫nico documento textual ‚Äî resultando em uma representa√ß√£o contextualizada e sem ru√≠do.
  * Esse texto passou por **vetoriza√ß√£o com TF-IDF**, otimizando a entrada para o modelo.

### 3\. üéØ Prepara√ß√£o do Alvo (Prepara√ß√£o do y)

  * O dataset de condi√ß√µes foi convertido de formato *longo* para *wide*, via `pandas.crosstab`, gerando um **DataFrame multi-r√≥tulo** (cada coluna = uma condi√ß√£o bin√°ria).
  * Exemplo:
    ```
    client_id | e66 | g47 | z72
         1    |  1  |  0  |  1
    ```

### 4\. ü§ñ Modelagem Baseline

  * Para criar uma Prova de Conceito (PoC) robusta, utilizei um pipeline cl√°ssico de NLP:
      * **Features:** `TfidfVectorizer` para extrair features do texto.
      * **Modelo:** `MultiOutputClassifier(LogisticRegression())` para lidar com a classifica√ß√£o multi-r√≥tulo.

## ‚ö†Ô∏è Insight Principal: A Limita√ß√£o de Dados

A investiga√ß√£o (o foco do desafio) revelou uma limita√ß√£o cr√≠tica:

| Tipo de Dado | N¬∫ de Clientes √önicos |
| :--- | :---: |
| Hist√≥rico de Chat (`X`) | 3 |
| Condi√ß√µes Rotuladas (`y`) | 2 |
| **Amostras Trein√°veis (X ‚à© y)** | **2** |

Com apenas 2 amostras de treino, a decis√£o foi **n√£o focar em m√©tricas de acur√°cia**, mas sim em **provar a arquitetura do pipeline**. Os artefatos (`model.joblib`, `vectorizer.joblib`) foram gerados para demonstrar que a API funciona de ponta-a-ponta.

## üöÄ Como Testar a API (Localmente)

A API possui um frontend simples para testes interativos.

```bash
# 1. Clone o reposit√≥rio e entre na pasta
git clone https://github.com/JonasMelo21/desafio-agile.git
cd desafio-agile

# 2. Crie e ative o ambiente virtual
python -m venv venv
source venv/bin/activate    # Linux/Mac (ou .\venv\Scripts\activate no Windows)

# 3. Instale as depend√™ncias
pip install -r requirements.txt

# 4. Rode a API
python api.py
```

Ap√≥s rodar, acesse **`http://127.0.0.1:5000/`** no seu navegador para usar a interface de teste.

**IDs para teste:**

  * `2` (Cliente presente no treino)
  * `3` (Cliente novo, fora do treino)
  * `999` (Cliente inexistente, retornar√° 404)

## üß© Destaques e Aprendizados

  * üß† **Capacidade de an√°lise sob limita√ß√£o de dados**, com foco na entrega de uma PoC funcional e n√£o na frustra√ß√£o pela falta de dados.
  * üèóÔ∏è **Pipeline NLP *end-to-end*** (Dados ‚Üí Modelo ‚Üí API) modular e reprodut√≠vel, pronto para ser expandido com novos dados.
  * üîç **NLP aplicado a contexto real** de linguagem cl√≠nica.
  * üß∞ **Entrega de valor agregado** com um frontend simples para testes e valida√ß√£o.
  * üöÄ **Clean code e documenta√ß√£o clara**, facilitando auditoria e evolu√ß√£o do projeto.

## üîÆ Pr√≥ximos Passos e Melhorias Futuras

O *pipeline* atual foi constru√≠do como uma Prova de Conceito robusta. Os pr√≥ximos passos l√≥gicos seriam:

1.  **Ingest√£o de Dados:** O primeiro passo seria obter um conjunto de dados de treino maior e mais representativo para permitir uma modelagem estat√≠stica real.
2.  **Modelagem NLP Avan√ßada:** Substituir o *baseline* (TF-IDF + Regress√£o Log√≠stica) por modelos de linguagem baseados em Transformers (ex: **BERTimbau**). Esses modelos entendem o contexto, a sem√¢ntica e as nega√ß√µes (ex: "eu *n√£o* tenho diabetes" vs. "eu tenho diabetes"), o que aumentaria drasticamente a acur√°cia.
3.  **Modelo Multimodal:** Utilizar os metadados dos clientes (`idade`, `genero`, `cidade`) que foram descartados neste *baseline*. Um modelo mais avan√ßado poderia combinar as *features* de texto (do BERT) com as *features* tabulares, criando um sistema de classifica√ß√£o mais completo.
4.  **Extra√ß√£o de Informa√ß√£o (IE) e *Weak Supervision*:** Usar os arquivos `seed_*.csv` (com crit√©rios de inclus√£o e exclus√£o) n√£o apenas como dicion√°rios, mas como base para um sistema de *Weak Supervision*. Poder√≠amos criar regras (ex: regex, spaCy) para identificar men√ß√µes a "glicose alta" ou "fumo" e us√°-las para rotular automaticamente milhares de chats, criando um conjunto de treino maior sem esfor√ßo manual.
